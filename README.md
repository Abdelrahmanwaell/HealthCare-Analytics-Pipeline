# ğŸ¥ Big Data Healthcare Pipeline - MIMIC-III Dataset

![Header](https://capsule-render.vercel.app/api?type=waving&color=0:00c651,100:0072ff&height=280&section=header&text=MIMIC-III%20Healthcare%20Analytics&fontSize=60&fontColor=ffffff&animation=fadeIn&fontAlign=center&fontAlignY=40&desc=Hadoop%20â€¢%20Hive%20â€¢%20MapReduce%20â€¢%20Docker%20&descSize=22&descAlign=middle&descAlignY=65)

[![Platform](https://img.shields.io/badge/Platform-Docker-2496ED?logo=docker&logoColor=white)](https://www.docker.com/)
[![Storage](https://img.shields.io/badge/Storage-HDFS-66ccff?logo=apachehadoop&logoColor=white)](https://hadoop.apache.org/)
[![Batch](https://img.shields.io/badge/Batch-Hive-FDEE21?logo=apachehive&logoColor=black)](https://hive.apache.org/)
[![Dataset](https://img.shields.io/badge/Dataset-MIMIC--III-7c4dff)](https://mimic.mit.edu/)
[![Compute](https://img.shields.io/badge/Compute-MapReduce-ED8B00?logo=apache&logoColor=white)](https://hadoop.apache.org/)
[![Format](https://img.shields.io/badge/Format-Parquet-50C878?logo=apacheparquet&logoColor=white)](https://parquet.apache.org/)

> **A scalable big data pipeline for healthcare analytics using MIMIC-III clinical data with Hadoop ecosystem components**

---

## ğŸ¯ Purpose
This project implements an end-to-end **big data pipeline** for processing and analyzing the MIMIC-III Clinical Database.The pipeline involves data cleaning using **Pandas**, conversion to **Parquet** format, storage in a containerized **HDFS** environment, and analysis using Apache **Hive**.

---

## ğŸ¯ Objectives
1. Implement distributed storage of MIMIC-III data using HDFS
2. Perform batch analytics with Hive for clinical insights
3. Demonstrate parallel processing with MapReduce
4. Containerize the big data environment using Docker
5. Generate healthcare analytics on:
   - Patient length of stay prediction
   - ICU readmission risk analysis
   - Demographic-based mortality rates
   - Diagnosis-related treatment patterns




---

## âš™ï¸ Key Components & Technologies
| Component | Technology | Purpose |
|-----------|-------------|---------|
| **Distributed Storage** | Hadoop HDFS | Scalable data storage |
| **Batch Processing** | Apache Hive | SQL-based analytics |
| **Data Processing** | MapReduce | Parallel computation |
| **Containerization** | Docker | Environment packaging |
| **Data Format** | Parquet | Columnar storage optimization |
| **Version Control** | Git/GitHub | Code management |

---

## ğŸ—ï¸ System Architecture
<div align="center">
  <img src="DOC/Architechture.jpg" alt="Big Data Pipeline Architecture" width="100%">
  <p><em>Complete data pipeline from MIMIC-III dataset to healthcare insights</em></p>
</div>

## ğŸ“ Project File Structure

ğŸ“ (Project Root)/
â”œâ”€â”€ ğŸ“„ README.md                   # Main project documentation
â”œâ”€â”€ ğŸ“‚ DOC/                        # Documentation and outputs
â”‚   â”œâ”€â”€ ğŸ“„ Architechture.jpg       # System architecture diagram
â”‚   â””â”€â”€ ğŸ“„ USER_MANUAL.pdf         # User manual for the pipeline
â”‚
â”œâ”€â”€ ğŸ“‚ Data/                       # All data assets
â”‚   â”œâ”€â”€ ğŸ“‚ processed-data/         # Cleaned and processed data
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ Admissions.csv
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ CUSTAYS.csv
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ CUSTAYS.parquet
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ admissions_parquet/     # Parquet-formatted data
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ diagnoses_lcd_parquet/  # Parquet-formatted data
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ patients.csv
â”‚   â”‚   â””â”€â”€ ğŸ“„ patients.parquet
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“‚ raw-data/               # Original source data
â”‚       â”œâ”€â”€ ğŸ“„ ADMISSIONS.csv
â”‚       â”œâ”€â”€ ğŸ“„ DIAGNOSES_ICD.csv
â”‚       â”œâ”€â”€ ğŸ“„ CUSTAYS.csv
â”‚       â”œâ”€â”€ ğŸ“„ LICENSE.txt
â”‚       â”œâ”€â”€ ğŸ“„ PATIENTS.csv
â”‚       â””â”€â”€ ğŸ“„ SHA256SUMS.txt
â”‚
â”œâ”€â”€ ğŸ“‚ hive/                       # Hive-related files
â”‚
â”œâ”€â”€ ğŸ“‚ hive-queries/               # Hive query scripts
â”‚   â””â”€â”€ ğŸ“„ hive-queries.txt
â”‚
â”œâ”€â”€ ğŸ“‚ hive-table/                 # Table creation scripts
â”‚   â””â”€â”€ ğŸ“„ create_table.txt
â”‚
â”œâ”€â”€ ğŸ“‚ MapReduce/                  # MapReduce components
â”‚
â”œâ”€â”€ ğŸ“‚ avg_classes/                # MapReduce implementation
â”‚   â”œâ”€â”€ ğŸ“„ AverageAge$AgeMapper.class
â”‚   â”œâ”€â”€ ğŸ“„ AverageAge$AverageReducer.class
â”‚   â”œâ”€â”€ ğŸ“„ AverageAge.class
â”‚   â”œâ”€â”€ ğŸ“„ AverageAge.java         #MapReduce java script
    â”œâ”€â”€ ğŸ“„ part-r-00000            #MapReduce output
â”‚   â””â”€â”€ ğŸ“„ average_age.jar
â”‚
â””â”€â”€ ğŸ“‚ python/                     # Data processing scripts
    â”œâ”€â”€ ğŸ“„ ICUstays.ipynb          # Jupyter notebook for ICU stays
    â”œâ”€â”€ ğŸ“„ admission.ipynb         # Jupyter notebook for admissions
    â”œâ”€â”€ ğŸ“„ clean.py                # Data cleaning script
    â”œâ”€â”€ ğŸ“„ diagnoses.ipynb         # Jupyter notebook for diagnoses
    â””â”€â”€ ğŸ“„ patients.ipynb          # Jupyter notebook for patients           
